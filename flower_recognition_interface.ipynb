{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769d1c36-dee5-45f7-97f7-f91f67826065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df6c5082-51b8-442b-b9b3-bc5196d9c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "195e40a9-9d26-49d7-a82f-d26cb33c4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "047312b6-2e60-4840-8058-30be7f40e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm xử lý từng khung hình và nhận dạng hoa\n",
    "def process_frame(frame):\n",
    "    # Thay đổi kích thước khung hình về kích thước mô hình yêu cầu (64x64) với interpolation hiệu quả\n",
    "    resized_frame = cv2.resize(frame, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "    # Chuẩn hóa khung hình từ [0, 255] về [0, 1]\n",
    "    normalized_frame = resized_frame.astype(np.float32) / 255.0\n",
    "    # Thêm chiều batch để phù hợp với input_shape của mô hình\n",
    "    expanded_frame = np.expand_dims(normalized_frame, axis=0)\n",
    "    # Dự đoán nhãn\n",
    "    predictions = model.predict(expanded_frame)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    # Trả về tên loại hoa\n",
    "    return class_names[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9020d29e-f189-44eb-bd44-351998f989f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm nhận dạng hoa trong video và trả về danh sách thời gian và nhãn hoa\n",
    "def recognize_flowers_in_video(video_file):\n",
    "    cap = cv2.VideoCapture(video_file.name)\n",
    "    results = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Lấy thời gian hiện tại trong video\n",
    "        time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0  # thời gian tính bằng giây\n",
    "        # Nhận dạng hoa trên khung hình\n",
    "        flower_name = process_frame(frame)\n",
    "        # Lưu kết quả với thời gian tương ứng\n",
    "        results.append((time, flower_name))\n",
    "\n",
    "    cap.release()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35923098-4dbe-41ac-9e4f-cdf7fafb998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm nhận dạng hoa từ ảnh\n",
    "def recognize_flowers_in_image(image_file):\n",
    "    results = []\n",
    "    # Mở ảnh từ tệp bằng PIL\n",
    "    image = Image.open(image_file.name).convert('RGB')\n",
    "    # Chuyển đổi ảnh thành mảng NumPy\n",
    "    image_np = np.array(image)\n",
    "    # Chuyển đổi ảnh về kích thước mà mô hình yêu cầu (64x64)\n",
    "    resized_image = cv2.resize(image_np, (64, 64))\n",
    "    # Chuyển đổi ảnh về định dạng mà mô hình yêu cầu\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Mở rộng chiều để phù hợp với input_shape của mô hình\n",
    "    expanded_image = np.expand_dims(normalized_image, axis=0)\n",
    "    # Dự đoán nhãn\n",
    "    predictions = model.predict(expanded_image)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    flower_name = class_names[predicted_class]\n",
    "    # Thêm kết quả vào danh sách\n",
    "    results.append((0, flower_name))  # Thời gian là 0 cho ảnh\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "032beacb-c233-4ccc-8692-290fbc676d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_processing(file):\n",
    "    # Kiểm tra kiểu đầu vào và gọi hàm xử lý tương ứng\n",
    "    if file.name.endswith('.mp4') or file.name.endswith('.avi'):\n",
    "        results = recognize_flowers_in_video(file)\n",
    "    else:\n",
    "        results = recognize_flowers_in_image(file)\n",
    "    \n",
    "    # Tạo danh sách hiển thị kết quả với tên loại hoa\n",
    "    display_results = [{\"Time (s)\": time, \"Flower Name\": flower_name} for time, flower_name in results]\n",
    "    return display_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddf16a48-e91b-4d2a-b3fb-d61c2112ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo giao diện Gradio\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_processing,\n",
    "    inputs=gr.File(label=\"Upload File\"),\n",
    "    outputs=gr.JSON(),\n",
    "    title=\"Flower Recognition\",\n",
    "    description=\"Upload an image or video to recognize flowers and get the results with timestamps.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2160d1e9-eb92-4379-9c09-567dfcb3d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 288, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1931, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1516, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\AppData\\Local\\Temp\\ipykernel_14052\\945346071.py\", line 4, in gradio_processing\n",
      "    results = recognize_flowers_in_video(file)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\AppData\\Local\\Temp\\ipykernel_14052\\3609310268.py\", line 14, in recognize_flowers_in_video\n",
      "    flower_name = process_frame(frame)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\AppData\\Local\\Temp\\ipykernel_14052\\23279678.py\", line 10, in process_frame\n",
      "    predictions = model.predict(expanded_frame)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Phan Tuan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(1, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Chạy ứng dụng Gradio\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984acc8-23c0-4a4e-8d84-86616d5f688c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
